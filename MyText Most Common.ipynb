{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of words that most often occur in a text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_text():\n",
    "    f = open('Text3.txt.','r')\n",
    "    t= f.read()\n",
    "    f.close()\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_of_text = '''Five days a week, for thirty-six years, I have travelled the eight-twelve train to the City. It is never unduly crowded, and it takes me right in to Gannon Street Station, only an eleven and a half minute walk from the door of my office in Austin Friars.\n",
    "I have always liked the process of commuting; every phase of the little journey is a pleasure to me. There is a regularity about it that is agreeable and comforting to a person of habit, and in addition, it serves as a sort of slipway along which I am gently but firmly launched into the waters of daily business routine.\n",
    "Ours is a smallish country station and-only nineteen or twenty people gather there to catch the eight-twelve. We are a group that rarely changes, and when occasionally a new face appears on the platform it causes a certain disclamatory, protestant ripple, like a new bird in a cage of canaries.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_most_common_lemms(text, count, stop_words): \n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    \n",
    "    tokens = [w.lower() for w in words if w.isalpha()]\n",
    "    \n",
    "    tokens_no_stop = [t for t in tokens if t not in stop_words]\n",
    "    \n",
    "    lemmatized_list = [lemmatizer.lemmatize(l) for l in tokens_no_stop]\n",
    "    \n",
    "    return Counter(lemmatized_list).most_common(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('would', 52), ('foxley', 36), ('time', 31), ('one', 23), ('like', 20)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_most_common_lemms(my_text(), 5, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('station', 2), ('new', 2), ('five', 1), ('day', 1), ('week', 1)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_most_common_lemms(part_of_text,5, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
